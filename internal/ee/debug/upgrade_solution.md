### 개선 방안
	워커풀 간 공유하는 자원의 병렬 수용성 높이기.
	BedgerDB, 그래프DB, 디포짓 DB등 DB의 병렬 읽기-쓰기 활성화 시키기.
	워커간 공유하는 아토믹 자원 등도 최소화하기
### 근거 자료: 워커풀 개수 조정하며 3회 테스트한 결과
16CPU상에서. 고속 모드로:
	워커풀이 32개 시: 1분간 처리량 14만tx.
	워커풀이 16개 시: 1분간 처리량 14만tx.
	워커풀이 4개 시: 1분간 처리량 15만tx. 
	워커풀이 2개 시: 1분간 처리량 14만tx.
	워커풀이 1개 시: 1분간 처리량 14만tx. 
공통적으로:
	카프카 콘슈머-워커풀 간 job채널 대해서, 워커풀 개수에 상관없이
	job 채널 블로킹이 발생함. job 채널이 다차서 0.1초간 콘슈밍 송신을 블로킹하는 로그가 찍힘
### 근거 자료의 해석
	현재 DB 커넥션 풀 병목 걸리는듯.
### 근거 자료 해석의 근거
    => 카프카IO가 원인일까 싶어서, 워커풀 컨슈밍 부분에 워커 블로킹 로그를 찍게 해 봤음
	=> 만약 워커 블로킹 로그가 안찍히는데도 워커풀 처리량 저하가 나오면 이는 카프카의 콘슈밍 속도가 느려서, 워커풀이 많다 해도 무용해지는 것이기 때문임. 때문에 처음엔 워커풀의 초당 처리량을 카프카의 초당 컨슈밍 양이 못 따라 가는 것을 의심했음.
	=> 근데 되려 워커 블로킹 로그가 아주 많이 찍히는 것임.
	=> 즉, 카프카는 워커풀 채널에 충분히 빠르게 많이 tx를 공부하고 있는 방면, 워커의 Do()자체가 느려서 병목이 된다는 것임.
	=> 이는 워커풀이 카프카 콘슈밍 속도를 따라가지 못하는 것. 
	=> 그렇다면 워커풀의 어디에서 느린 것인가?
	=> 크게 두 가지임. CPU병목이거나, DB병목이거나
	=> 이때, 워커풀의 워커 수 조절 통해서 스레드 수를 10배까지 끌어올려도 TPS가 동일함
	=> 이는, "스레드 간 경합" 발생의 증거임
	=> 즉, 공유 자원에서 블로킹이 발생하는 것.
	=> 이는, "DB"혹은 "여타 공유 자원"의 접근이 아주 큰 병목임을 시사함.
	=> 현재 그 "공유자원"은 아토믹 자원과 DB자원이 대표적으로 존재함.