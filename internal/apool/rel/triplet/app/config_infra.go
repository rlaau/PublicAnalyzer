package app

import (
	"context"
	"fmt"
	"log"
	"os"
	"strings"
	"time"

	"github.com/rlaaudgjs5638/chainAnalyzer/internal/apool/rel/triplet/infra"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/computation"
	shareddomain "github.com/rlaaudgjs5638/chainAnalyzer/shared/domain"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/kafka"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/mode"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/workflow/workerpool"
)

func NewInfraByConfig(config *TripletConfig, ctx context.Context) infra.TotalEOAAnalyzerInfra {
	var isolateColusre = computation.ComputeRelClosure(config.IsolatedDBPath)
	log.Printf("EOA Analyzerì˜ Infra ì„¸íŒ… ì¤‘: %s (Mode: %s)", config.Name, config.Mode)
	cexSet, err := loadCEXSet(isolateColusre("cex.txt"))
	if err != nil {
		fmt.Printf("CEX setë¡œë”© ì¤‘ ì—ëŸ¬ë‚¨.")
		panic("ë” ì´ìƒ ì‘ì—… ë¶ˆê°€")
	}
	fmt.Printf("CEX ë¡œë“œ ì™„ë£Œ")
	depositRepo, err := loadDetectedDepositSet(config.IsolatedDBPath, config.Mode)
	if err != nil {
		fmt.Printf("ë””í¬ì§“ ë¡œë”© ì‹¤íŒ¨. (íŒŒì¼ ê²½ë¡œ: %s)", config.IsolatedDBPath)
	}
	groundKnowledge := infra.NewDomainKnowledge(cexSet, depositRepo)
	if err := groundKnowledge.Load(); err != nil {
		panic("ê·¸ë¼ìš´ë“œ ë†€ë¦¬ì§€ë¥¼ íŒŒì¼->(ë©”ëª¨ë¦¬,íŒŒì¼)ë¡œ ë¡œë“œí•˜ì§€ ëª»í•¨")
	}
	log.Printf("ğŸ§  Ground knowledge loaded")

	batchConsumer := loadKafkaBatchConsumer(config.Mode, config.Name)
	//* ì›Œì»¤ í’€ì— ì“¸ ì±„ë„ ìƒì„±
	txJobChannel := make(chan workerpool.Job, config.ChannelBufferSize)
	//* ì›Œì»¤í’€ ìƒì„± ë° ì±„ë„ ë“±ë¡
	workerPool := workerpool.New(ctx, config.WorkerCount, txJobChannel)
	log.Printf("ğŸ”§ WorkerPool initialized with %d workers", config.WorkerCount)
	pendingDB, err := infra.NewFFBadgerPendingRelationRepo(isolateColusre("pending"))
	if err != nil {
		panic("íœë”œ ë ˆí¬ì§€í† ë¦¬ë¥¼ ì—´ì§€ ëª»í•¨.")
	}
	return *infra.NewEOAInfra(groundKnowledge, txJobChannel, workerPool, batchConsumer, pendingDB)

}

func loadKafkaBatchConsumer(mode mode.ProcessingMode, name string) *kafka.KafkaBatchConsumer[*shareddomain.MarkedTransaction] {
	// Transaction Consumer ì´ˆê¸°í™” - ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ í† í”½ ì‚¬ìš©
	kafkaBrokers := []string{kafka.DefaultKafkaPort}
	isTestMode := mode.IsTest()
	groupID := fmt.Sprintf("triplet-analyzer-%s", strings.ReplaceAll(name, " ", "-"))
	// ë°°ì¹˜ ëª¨ë“œ Consumer ì´ˆê¸°í™” (ê³ ì„±ëŠ¥)
	batchSize := 100                      // 100ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
	batchTimeout := 20 * time.Millisecond // 20ms íƒ€ì„ì•„ì›ƒ
	var topic string
	if isTestMode {
		topic = kafka.TestFedTxTopic // í…ŒìŠ¤íŠ¸ìš© í† í”½
	} else {
		topic = kafka.ProductionTxTopic // í”„ë¡œë•ì…˜ìš© í† í”½
	}

	consumerConfig := kafka.KafkaBatchConfig{
		Brokers:      kafkaBrokers,
		Topic:        topic,
		GroupID:      groupID,
		BatchSize:    batchSize,
		BatchTimeout: batchTimeout,
	}
	batchConsumer := kafka.NewKafkaBatchConsumer[*shareddomain.MarkedTransaction](consumerConfig)
	log.Printf("ğŸ“¡ Batch consumer initialized (test mode: %v, batch size: %d)", isTestMode, batchSize)
	return batchConsumer
}
func loadCEXSet(cexFilePath string) (*shareddomain.CEXSet, error) {
	if cexFilePath == "" {
		// ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (í›„ë°© í˜¸í™˜ì„±)
		cexFilePath = "internal/triplet/cex.txt"
	}
	cexRepo := infra.NewFileCEXRepository(cexFilePath)
	cexSet, err := cexRepo.LoadCEXSet()
	if err != nil {
		return nil, fmt.Errorf("failed to load CEX set from %s: %w", cexFilePath, err)
	}
	return cexSet, nil
}
func loadDetectedDepositSet(fileDBPath string, mode mode.ProcessingMode) (*infra.FileDepositRepository, error) {
	// ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
	if err := os.MkdirAll(fileDBPath, 0755); err != nil {
		return nil, fmt.Errorf("failed to create data directory: %w", err)
	}
	// Deposit ì €ì¥ì†Œ ì´ˆê¸°í™” - ëª¨ë“œì— ë”°ë¥¸ ê²½ë¡œ ì„¤ì •
	var detectedDepositFilePath string
	//TODO ë¡œì§ì€ ê·¸ëŸ´ë“¯ í•˜ì§€ë§Œ, FileDBPathìì²´ê°€ Isolated í´ë” ë‚´ë¶€ë¼ ì‹¤ì€ íš¨ìš©ì´ ì—†ìŒ. ì¶”í›„ isolatedê´€ë ¨ feed_XX_XX.goìˆ˜ì • í•„ìš”.
	//TODO í…ŒìŠ¤íŠ¸ ì‹œì—ë§Œ isolatedë˜ê²Œ í•´ì•¼ í•¨.
	if mode.IsTest() {
		detectedDepositFilePath = fileDBPath + "/test_detected_deposits.csv"
	} else {
		detectedDepositFilePath = fileDBPath + "/production_detected_deposits.csv"
	}
	depositRepo := infra.NewFileDepositRepository(detectedDepositFilePath)
	return depositRepo, nil
}
