package app

import (
	"bufio"
	"context"
	"fmt"
	"io"
	"math/big"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	sharedDomain "github.com/rlaaudgjs5638/chainAnalyzer/shared/domain"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/kafka"
	"github.com/rlaaudgjs5638/chainAnalyzer/shared/txfeeder/domain"
)

// EnvironmentConfig í™˜ê²½ ì„¤ì •ì„ ìœ„í•œ êµ¬ì¡°ì²´ (ê¸°ì¡´ í˜¸í™˜ì„±ìš©)
type EnvironmentConfig struct {
	BaseDir         string
	IsolatedDir     string
	CEXFilePath     string
	MockDepositFile string
	GraphDBPath     string
	PendingDBPath   string

	// Pipeline ì„¤ì •
	ChannelBufferSize int
	TestDuration      time.Duration
	TotalTransactions int
	GenerationRate    int
	AnalysisWorkers   int
}

// AdditionalDataConfig ì¶”ê°€ ë°ì´í„° ì„¤ì •ì„ ìœ„í•œ êµ¬ì¡°ì²´ (í–¥í›„ í™•ì¥ìš©)
type AdditionalDataConfig struct {
	// í–¥í›„ ì¶”ê°€ ë°ì´í„° ê´€ë ¨ ì„¤ì •ë“¤ì´ ë“¤ì–´ê°ˆ ì˜ˆì •
	// ì¼ë‹¨ ë¹„ì›Œë‘ê³  ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ í™•ì¥
}

// TxFeederConfig í†µí•©ëœ TxFeeder ì„¤ì •
type TxFeederConfig struct {
	// íŠ¸ëœì­ì…˜ ìƒì„± ì„¤ì •
	GenConfig *domain.TxGeneratorConfig

	// í™˜ê²½ ì„¤ì •
	EnvConfig *EnvironmentConfig

	// ì¶”ê°€ ë°ì´í„° ì„¤ì • (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
	AdditionalDataConfig *AdditionalDataConfig

	// ë°°ì¹˜ ëª¨ë“œ ì„¤ì •
	BatchMode    bool          // ë°°ì¹˜ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
	BatchSize    int           // ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 100)
	BatchTimeout time.Duration // ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ê°’: 50ms)
}

// PipelineStats íŒŒì´í”„ë¼ì¸ í†µê³„
type PipelineStats struct {
	Generated   int64 // ìƒì„±ëœ íŠ¸ëœì­ì…˜ ìˆ˜
	Transmitted int64 // ì „ì†¡ëœ íŠ¸ëœì­ì…˜ ìˆ˜
	Processed   int64 // ì²˜ë¦¬ëœ íŠ¸ëœì­ì…˜ ìˆ˜
	Dropped     int64 // ë“œë¡­ëœ íŠ¸ëœì­ì…˜ ìˆ˜ (ì±„ë„ í’€)
	StartTime   time.Time
}

// DebugStats ë””ë²„ê¹…ìš© í†µê³„
type DebugStats struct {
	CexToAddresses     int64 // CEXë¥¼ toë¡œ í•˜ëŠ” íŠ¸ëœì­ì…˜
	DepositToAddresses int64 // Depositì„ toë¡œ í•˜ëŠ” íŠ¸ëœì­ì…˜
	RandomTransactions int64 // ëœë¤ íŠ¸ëœì­ì…˜
	MatchFailures      int64 // ë§¤ì¹­ ì‹¤íŒ¨
}

// TxFeeder generates transactions for testing EE module with pipeline management
type TxFeeder struct {
	config           *domain.TxGeneratorConfig
	state            *domain.TxGeneratorState
	mockDepositAddrs *domain.MockDepositAddressSet
	cexSet           *sharedDomain.CEXSet

	// Channels for transaction output (backward compatibility)
	markedTxChannel chan sharedDomain.MarkedTransaction

	// Kafka producer for fed-tx topic
	kafkaProducer *kafka.KafkaProducer[*sharedDomain.MarkedTransaction]
	batchProducer *kafka.KafkaBatchProducer[*sharedDomain.MarkedTransaction] // ë°°ì¹˜ ëª¨ë“œìš© í”„ë¡œë“€ì„œ (ì œë„ˆë¦­)
	kafkaBrokers  []string
	batchMode     bool          // ë°°ì¹˜ ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
	batchSize     int           // ë°°ì¹˜ í¬ê¸°
	batchTimeout  time.Duration // ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ

	// Control channels
	stopChannel chan struct{}
	doneChannel chan struct{}

	// Synchronization
	mutex    sync.RWMutex
	stopOnce sync.Once // ì¤‘ë³µ stop ë°©ì§€

	// Environment management
	baseDir     string
	isolatedDir string

	// Pipeline management - ì¶œë ¥ ì±„ë„ ë“±ë¡ ë°©ì‹ (backward compatibility)
	requestedOutputChannels []chan<- *sharedDomain.MarkedTransaction // ë“±ë¡ëœ ì¶œë ¥ ì±„ë„ë“¤

	// Pipeline í†µê³„ ë° ìƒíƒœ ê´€ë¦¬
	stats       PipelineStats
	debugStats  DebugStats
	wg          sync.WaitGroup
	channelOnce sync.Once // íŠ¸ëœì­ì…˜ ì±„ë„ ì¤‘ë³µ ë‹«ê¸° ë°©ì§€
}

// NewTxFeeder ê°„ë‹¨í•œ TxFeeder ìƒì„±ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
func NewTxFeeder(genConfig *domain.TxGeneratorConfig, envConfig *EnvironmentConfig) (*TxFeeder, error) {
	config := &TxFeederConfig{
		GenConfig:            genConfig,
		EnvConfig:            envConfig,
		AdditionalDataConfig: nil, // í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
	}

	return NewTxFeederWithComplexConfig(config)
}

// NewTxFeederWithComplexConfig í†µí•©ëœ ì„¤ì •ìœ¼ë¡œ TxFeederë¥¼ ìƒì„±í•˜ê³  ëª¨ë“  ì´ˆê¸°í™”ë¥¼ ì™„ë£Œ
func NewTxFeederWithComplexConfig(config *TxFeederConfig) (*TxFeeder, error) {
	// 1. ê¸°ë³¸ TxFeeder ìƒì„± (ë¹ˆ CEXSetìœ¼ë¡œ ì‹œì‘)
	emptyCexSet := sharedDomain.NewCEXSet()
	feeder := GetRawTxFeeder(config.GenConfig, emptyCexSet)

	// 2. ë°°ì¹˜ ëª¨ë“œ ì„¤ì • ì ìš©
	if config.BatchMode {
		feeder.EnableBatchMode(config.BatchSize, config.BatchTimeout)
	}

	// 3. í™˜ê²½ ì„¤ì •ì´ ìˆìœ¼ë©´ ì‹¤í–‰
	if config.EnvConfig != nil {
		if err := feeder.SetupEnvironment(config.EnvConfig); err != nil {
			return nil, fmt.Errorf("failed to setup environment: %w", err)
		}

		// CEX Set ë¡œë”©
		if _, err := feeder.LoadCEXSetFromFile(config.EnvConfig.CEXFilePath); err != nil {
			return nil, fmt.Errorf("failed to load CEX set: %w", err)
		}

		// Mock Deposit ì£¼ì†Œ ë¡œë”©
		if err := feeder.LoadMockDepositAddresses(config.EnvConfig.MockDepositFile); err != nil {
			return nil, fmt.Errorf("failed to load mock deposits: %w", err)
		}
	}

	// 4. AdditionalDataConfigëŠ” í˜„ì¬ ë¬´ì‹œ (í–¥í›„ í™•ì¥ìš©)
	// if config.AdditionalDataConfig != nil {
	//     // í–¥í›„ ì¶”ê°€ ë°ì´í„° ì„¤ì • ì²˜ë¦¬
	// }

	return feeder, nil
}

// GetRawTxFeeder creates a new transaction generator with pipeline capabilities (ê¸°ì¡´ í˜¸í™˜ì„±ìš©)
func GetRawTxFeeder(config *domain.TxGeneratorConfig, cexSet *sharedDomain.CEXSet) *TxFeeder {
	// Kafka ë¸Œë¡œì»¤ ì„¤ì • (ê¸°ë³¸ê°’: localhost:9092)
	kafkaBrokers := []string{"localhost:9092"}

	// Kafka Producer ì´ˆê¸°í™” (ê¸°ë³¸ê°’: ë‹¨ê±´ ëª¨ë“œ)
	kafkaConfig := kafka.KafkaBatchConfig{
		Brokers: kafkaBrokers,
		Topic:   kafka.TestFedTxTopic}
	kafkaProducer := kafka.NewKafkaProducer[*sharedDomain.MarkedTransaction](kafkaConfig)

	return &TxFeeder{
		config:                  config,
		state:                   domain.NewTxGeneratorState(config.StartTime, config.TimeIncrementDuration, config.TransactionsPerTimeIncrement),
		mockDepositAddrs:        domain.NewMockDepositAddressSet(),
		cexSet:                  cexSet,
		markedTxChannel:         make(chan sharedDomain.MarkedTransaction, 100_000), // Buffer for 10k transactions
		kafkaProducer:           kafkaProducer,
		batchProducer:           nil, // ê¸°ë³¸ê°’: ë°°ì¹˜ ëª¨ë“œ ë¹„í™œì„±í™”
		kafkaBrokers:            kafkaBrokers,
		batchMode:               false,                 // ê¸°ë³¸ê°’: ë‹¨ê±´ ëª¨ë“œ
		batchSize:               100,                   // ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
		batchTimeout:            50 * time.Millisecond, // ê¸°ë³¸ ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ
		stopChannel:             make(chan struct{}),
		doneChannel:             make(chan struct{}),
		requestedOutputChannels: make([]chan<- *sharedDomain.MarkedTransaction, 0),
		stats: PipelineStats{
			StartTime: time.Now(),
		},
		debugStats: DebugStats{},
	}
}

// EnableBatchMode ë°°ì¹˜ ëª¨ë“œ í™œì„±í™”
func (g *TxFeeder) EnableBatchMode(batchSize int, batchTimeout time.Duration) error {
	g.mutex.Lock()
	defer g.mutex.Unlock()

	// ë°°ì¹˜ ì„¤ì • ì ìš© (ê¸°ë³¸ê°’ ì²˜ë¦¬)
	if batchSize <= 0 {
		batchSize = 100 // ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
	}
	if batchTimeout <= 0 {
		batchTimeout = 50 * time.Millisecond // ê¸°ë³¸ ë°°ì¹˜ íƒ€ì„ì•„ì›ƒ
	}

	g.batchMode = true
	g.batchSize = batchSize
	g.batchTimeout = batchTimeout

	// BatchProducer ì´ˆê¸°í™” (ì œë„ˆë¦­ íƒ€ì… ì‚¬ìš©)
	config := kafka.KafkaBatchConfig{
		Brokers:      g.kafkaBrokers,
		Topic:        kafka.TestFedTxTopic,
		GroupID:      "tx-feeder-batch-group",
		BatchSize:    batchSize,
		BatchTimeout: batchTimeout,
	}
	g.batchProducer = kafka.NewKafkaBatchProducer[*sharedDomain.MarkedTransaction](config)

	fmt.Printf("ğŸš€ Batch mode enabled: batchSize=%d, timeout=%v\n", batchSize, batchTimeout)
	return nil
}

// DisableBatchMode ë°°ì¹˜ ëª¨ë“œ ë¹„í™œì„±í™” (ë‹¨ê±´ ëª¨ë“œë¡œ ë³µê·€)
func (g *TxFeeder) DisableBatchMode() error {
	g.mutex.Lock()
	defer g.mutex.Unlock()

	if g.batchProducer != nil {
		g.batchProducer.Close()
		g.batchProducer = nil
	}

	g.batchMode = false
	fmt.Println("ğŸ”„ Switched to single-message mode")
	return nil
}

// IsBatchMode í˜„ì¬ ë°°ì¹˜ ëª¨ë“œ ì—¬ë¶€ í™•ì¸
func (g *TxFeeder) IsBatchMode() bool {
	g.mutex.RLock()
	defer g.mutex.RUnlock()
	return g.batchMode
}

// LoadMockDepositAddresses loads mock deposit addresses from file
func (g *TxFeeder) LoadMockDepositAddresses(filePath string) error {
	return g.mockDepositAddrs.LoadFromFile(filePath)
}

// Start begins transaction generation
func (g *TxFeeder) Start(ctx context.Context) error {
	// Kafka ì—°ê²° ìƒíƒœ í™•ì¸
	if err := kafka.EnsureKafkaConnection(g.kafkaBrokers); err != nil {
		return fmt.Errorf("kafka connection failed: %w", err)
	}

	// fed-tx í† í”½ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
	if err := kafka.CreateTopicIfNotExists(g.kafkaBrokers, kafka.TestFedTxTopic, 1, 1); err != nil {
		return fmt.Errorf("failed to ensure fed-tx topic: %w", err)
	}

	// ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ìƒì„± ë¡œì§ ì‹¤í–‰
	if g.IsBatchMode() {
		go g.generateTransactionsBatch(ctx)
	} else {
		go g.generateTransactions(ctx)
	}
	return nil
}

// Stop stops transaction generation (safe for multiple calls)
func (g *TxFeeder) Stop() {
	g.stopOnce.Do(func() {
		close(g.stopChannel)
	})
	<-g.doneChannel
}

// GetTxChannel returns the channel for receiving generated transactions
func (g *TxFeeder) GetTxChannel() <-chan sharedDomain.MarkedTransaction {
	return g.markedTxChannel
}

// GetGeneratedCount returns the current count of generated transactions
func (g *TxFeeder) GetGeneratedCount() int64 {
	g.mutex.RLock()
	defer g.mutex.RUnlock()
	return g.state.GeneratedCount
}

// RegisterOutputChannel registers a channel to receive generated transactions
func (g *TxFeeder) RegisterOutputChannel(outputCh chan<- *sharedDomain.MarkedTransaction) {
	g.mutex.Lock()
	defer g.mutex.Unlock()
	g.requestedOutputChannels = append(g.requestedOutputChannels, outputCh)
}

// GetPipelineStats returns current pipeline statistics with TPS
func (g *TxFeeder) GetPipelineStats() PipelineStats {
	generated := atomic.LoadInt64(&g.stats.Generated)
	transmitted := atomic.LoadInt64(&g.stats.Transmitted)

	return PipelineStats{
		Generated:   generated,
		Transmitted: transmitted,
		Processed:   atomic.LoadInt64(&g.stats.Processed),
		Dropped:     atomic.LoadInt64(&g.stats.Dropped),
		StartTime:   g.stats.StartTime,
	}
}

// GetTPS í˜„ì¬ TPS (ì´ˆë‹¹ íŠ¸ëœì­ì…˜ ìˆ˜) ë°˜í™˜
func (g *TxFeeder) GetTPS() float64 {
	generated := atomic.LoadInt64(&g.stats.Generated)
	elapsed := time.Since(g.stats.StartTime).Seconds()
	if elapsed > 0 {
		return float64(generated) / elapsed
	}
	return 0
}

// generateTransactions is the main generation loop running in goroutine
func (g *TxFeeder) generateTransactions(ctx context.Context) {
	defer close(g.doneChannel)
	defer close(g.markedTxChannel)
	fmt.Printf("Starting transaction generation: %d total transactions at %d tx/sec\n",
		g.config.TotalTransactions, g.config.TransactionsPerSecond)
	// Calculate dynamic interval based on config.TPS
	interval := time.Second / time.Duration(g.config.TransactionsPerSecond)
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Transaction generation stopped by context")
			return
		case <-g.stopChannel:
			fmt.Println("Transaction generation stopped by stop signal")
			return
		case <-ticker.C:
			// Check if we've generated enough transactions
			g.mutex.RLock()
			currentCount := g.state.GeneratedCount
			g.mutex.RUnlock()

			if currentCount >= int64(g.config.TotalTransactions) {
				fmt.Printf("Generated all %d transactions. Stopping.\n", g.config.TotalTransactions)
				return
			}

			// Generate transaction
			tx := g.generateSingleTransaction()
			atomic.AddInt64(&g.stats.Generated, 1)

			// Send to legacy channel (for backward compatibility)
			select {
			case g.markedTxChannel <- tx:
			case <-ctx.Done():
				return
			case <-g.stopChannel:
				return
			default:
				atomic.AddInt64(&g.stats.Dropped, 1)
			}

			// Send to all registered output channels (backward compatibility)
			g.sendToOutputChannels(&tx, ctx)

			// Send to Kafka topic
			g.sendToKafka(&tx, ctx)
		}
	}
}

// generateTransactionsBatch ë°°ì¹˜ ëª¨ë“œ íŠ¸ëœì­ì…˜ ìƒì„± (ì§„ì •í•œ ë°°ì¹­)
func (g *TxFeeder) generateTransactionsBatch(ctx context.Context) {
	defer close(g.doneChannel)
	defer close(g.markedTxChannel)

	fmt.Printf("ğŸš€ Starting BATCH transaction generation: %d total transactions at %d tx/sec (batch size: %d)\n",
		g.config.TotalTransactions, g.config.TransactionsPerSecond, g.batchSize)

	// ë°°ì¹˜ ê°„ê²© ê³„ì‚°: ë°°ì¹˜ í¬ê¸°ë§Œí¼ ìƒì„±í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„
	batchInterval := time.Duration(g.batchSize) * time.Second / time.Duration(g.config.TransactionsPerSecond)
	ticker := time.NewTicker(batchInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			fmt.Println("Batch transaction generation stopped by context")
			return
		case <-g.stopChannel:
			fmt.Println("Batch transaction generation stopped by stop signal")
			return
		case <-ticker.C:
			// ìƒì„±í•  ë°°ì¹˜ í¬ê¸° ê²°ì • (ë‚¨ì€ íŠ¸ëœì­ì…˜ ìˆ˜ ê³ ë ¤)
			g.mutex.RLock()
			currentCount := g.state.GeneratedCount
			g.mutex.RUnlock()

			remainingTx := int64(g.config.TotalTransactions) - currentCount
			if remainingTx <= 0 {
				fmt.Printf("Generated all %d transactions. Stopping batch mode.\n", g.config.TotalTransactions)
				return
			}

			// ì‹¤ì œ ë°°ì¹˜ í¬ê¸° ê²°ì • (ë‚¨ì€ íŠ¸ëœì­ì…˜ì´ ë°°ì¹˜ í¬ê¸°ë³´ë‹¤ ì‘ìœ¼ë©´ ì¡°ì •)
			actualBatchSize := g.batchSize
			if remainingTx < int64(g.batchSize) {
				actualBatchSize = int(remainingTx)
			}

			// ë°°ì¹˜ ìƒì„± ë° ì „ì†¡
			if err := g.generateAndSendBatch(ctx, actualBatchSize); err != nil {
				fmt.Printf("âš ï¸ Batch generation error: %v\n", err)
				continue
			}
		}
	}
}

// generateAndSendBatch ë°°ì¹˜ ìƒì„± ë° ì „ì†¡ (ì§„ì •í•œ ë°°ì¹­)
func (g *TxFeeder) generateAndSendBatch(ctx context.Context, batchSize int) error {
	// 1. ë°°ì¹˜ í¬ê¸°ë§Œí¼ íŠ¸ëœì­ì…˜ ìƒì„±
	transactions := make([]*sharedDomain.MarkedTransaction, 0, batchSize)
	messages := make([]kafka.Message[*sharedDomain.MarkedTransaction], 0, batchSize)

	for i := 0; i < batchSize; i++ {
		// íŠ¸ëœì­ì…˜ ìƒì„±
		tx := g.generateSingleTransaction()
		transactions = append(transactions, &tx)

		// íƒ€ì…í™”ëœ Kafka ë©”ì‹œì§€ ìƒì„± (ì§ì ‘ MarkedTransaction ì „ì†¡)
		messages = append(messages, kafka.Message[*sharedDomain.MarkedTransaction]{
			Key:   []byte("tx"),
			Value: &tx, // ì§ì ‘ MarkedTransaction í¬ì¸í„° ì „ì†¡
		})
	}

	// 2. í†µê³„ ì—…ë°ì´íŠ¸
	atomic.AddInt64(&g.stats.Generated, int64(len(transactions)))

	// 3. Legacy ì±„ë„ë“¤ì— ì „ì†¡ (backward compatibility)
	g.sendBatchToLegacyChannels(transactions, ctx)

	// 4. Kafka ë°°ì¹˜ ì „ì†¡ (ì§„ì •í•œ ë°°ì¹­!)
	if err := g.sendBatchToKafka(messages, ctx); err != nil {
		return fmt.Errorf("batch kafka send failed: %w", err)
	}

	return nil
}

// sendBatchToLegacyChannels ë°°ì¹˜ë¥¼ ë ˆê±°ì‹œ ì±„ë„ë“¤ì— ì „ì†¡
func (g *TxFeeder) sendBatchToLegacyChannels(transactions []*sharedDomain.MarkedTransaction, ctx context.Context) {
	for _, tx := range transactions {
		// Legacy channel (backward compatibility)
		select {
		case g.markedTxChannel <- *tx:
		case <-ctx.Done():
			return
		case <-g.stopChannel:
			return
		default:
			atomic.AddInt64(&g.stats.Dropped, 1)
		}

		// Registered output channels (backward compatibility)
		g.sendToOutputChannels(tx, ctx)
	}
}

// sendBatchToKafka ë°°ì¹˜ë¥¼ Kafkaì— ì „ì†¡ (ì§„ì •í•œ ë°°ì¹­)
func (g *TxFeeder) sendBatchToKafka(messages []kafka.Message[*sharedDomain.MarkedTransaction], ctx context.Context) error {
	if g.batchProducer == nil {
		return fmt.Errorf("batch producer not initialized")
	}

	// ì§„ì •í•œ ë°°ì¹˜ ì „ì†¡ (í•œ ë²ˆì˜ ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œë¡œ ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡)
	if err := g.batchProducer.PublishMessagesBatch(ctx, messages); err != nil {
		// ë°°ì¹˜ ì „ì²´ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
		atomic.AddInt64(&g.stats.Dropped, int64(len(messages)))
		return err
	} else {
		// ë°°ì¹˜ ì „ì²´ê°€ ì„±ê³µí•œ ê²½ìš°
		atomic.AddInt64(&g.stats.Transmitted, int64(len(messages)))
	}

	return nil
}

// generateSingleTransaction generates a single MarkedTransaction
func (g *TxFeeder) generateSingleTransaction() sharedDomain.MarkedTransaction {
	g.mutex.Lock()
	defer g.mutex.Unlock()

	// Determine transaction type based on patterns
	txType := g.determineTransactionType()

	var tx sharedDomain.MarkedTransaction

	switch txType {
	case DepositToCexTx:
		tx = g.generateDepositToCexTransaction()
		// ì²˜ìŒ 5ê°œ íŠ¹ë³„ ì¼€ì´ìŠ¤ëŠ” ë¡œê¹…
		if g.state.GeneratedCount < 5 && txType == DepositToCexTx {
			fmt.Printf("   âœ¨ Generated Depositâ†’CEX: From=%s â†’ To=%s\n",
				tx.From.String()[:10]+"...", tx.To.String()[:10]+"...")
		}
	case RandomToDepositTx:
		tx = g.generateRandomToDepositTransaction()
		if g.state.GeneratedCount < 5 && txType == RandomToDepositTx {
			fmt.Printf("   âœ¨ Generated Randomâ†’Deposit: From=%s â†’ To=%s\n",
				tx.From.String()[:10]+"...", tx.To.String()[:10]+"...")
		}
	default:
		tx = g.generateRandomTransaction()
	}

	// Update state
	g.state.IncrementTransaction()

	return tx
}

type TransactionType int

const (
	RandomTx          TransactionType = iota
	DepositToCexTx                    // mockedAndHiddenDepositAddress -> CEX
	RandomToDepositTx                 // random address -> mockedAndHiddenDepositAddress
)

func (t TransactionType) String() string {
	switch t {
	case RandomTx:
		return "Random"
	case DepositToCexTx:
		return "Depositâ†’CEX"
	case RandomToDepositTx:
		return "Randomâ†’Deposit"
	default:
		return "Unknown"
	}
}

// determineTransactionType determines what type of transaction to generate
func (g *TxFeeder) determineTransactionType() TransactionType {
	count := int(g.state.GeneratedCount)

	// ë””ë²„ê¹…: ì²˜ìŒ 10ê°œ íŠ¸ëœì­ì…˜ì˜ íƒ€ì… ê²°ì • ê³¼ì • ë¡œê¹…
	var txType TransactionType
	var reason string

	// 1 in 5 chance for DepositToCex transaction
	if count%g.config.DepositToCexRatio == 0 {
		txType = DepositToCexTx
		reason = fmt.Sprintf("count=%d %% %d == 0", count, g.config.DepositToCexRatio)
	} else if count%g.config.RandomToDepositRatio == 0 {
		// 1 in 8 chance for RandomToDeposit transaction
		txType = RandomToDepositTx
		reason = fmt.Sprintf("count=%d %% %d == 0", count, g.config.RandomToDepositRatio)
	} else {
		txType = RandomTx
		reason = fmt.Sprintf("count=%d, random", count)
	}

	// ì²˜ìŒ 10ê°œëŠ” ë””ë²„ê¹… ì¶œë ¥
	if count < 10 {
		fmt.Printf("   ğŸ² TX #%d: %v (%s)\n", count, txType, reason)
	}

	return txType
}

// generateDepositToCexTransaction generates mockedDepositAddress -> CEX transaction
func (g *TxFeeder) generateDepositToCexTransaction() sharedDomain.MarkedTransaction {
	fromAddr := g.mockDepositAddrs.GetRandomAddress()
	toAddr := g.getRandomCexAddress()

	return g.createMarkedTransaction(fromAddr, toAddr)
}

// generateRandomToDepositTransaction generates random -> mockedDepositAddress transaction
func (g *TxFeeder) generateRandomToDepositTransaction() sharedDomain.MarkedTransaction {
	fromAddr := domain.GenerateRandomAddress()
	toAddr := g.mockDepositAddrs.GetRandomAddress()

	return g.createMarkedTransaction(fromAddr, toAddr)
}

// generateRandomTransaction generates a completely random transaction
func (g *TxFeeder) generateRandomTransaction() sharedDomain.MarkedTransaction {
	fromAddr := domain.GenerateRandomAddress()
	toAddr := domain.GenerateRandomAddress()

	return g.createMarkedTransaction(fromAddr, toAddr)
}

// createMarkedTransaction creates a MarkedTransaction with given from/to addresses
func (g *TxFeeder) createMarkedTransaction(from, to sharedDomain.Address) sharedDomain.MarkedTransaction {
	txID := domain.GenerateRandomTxID()

	// Generate random value (0.1 to 10 ETH in wei)
	minWei := new(big.Int)
	minWei.SetString("100000000000000000", 10) // 0.1 ETH in wei
	maxWei := new(big.Int)
	maxWei.SetString("10000000000000000000", 10) // 10 ETH in wei
	diff := new(big.Int).Sub(maxWei, minWei)

	// Simple random generation for value
	randomBytes := make([]byte, 8)
	for i := range randomBytes {
		randomBytes[i] = byte(g.state.GeneratedCount >> (i * 8))
	}
	randomValue := new(big.Int).SetBytes(randomBytes)
	randomValue.Mod(randomValue, diff)
	randomValue.Add(randomValue, minWei)

	return sharedDomain.MarkedTransaction{
		BlockTime: g.state.CurrentTime,
		TxID:      txID,
		TxSyntax:  [2]sharedDomain.ContractBoolMark{sharedDomain.EOAMark, sharedDomain.EOAMark}, // Assume EOA-to-EOA for simplicity
		Nonce:     uint64(g.state.GeneratedCount),
		From:      from,
		To:        to,
	}
}

// getRandomCexAddress returns a random CEX address from the loaded set
func (g *TxFeeder) getRandomCexAddress() sharedDomain.Address {
	addresses := g.cexSet.GetAll()
	if len(addresses) == 0 {
		return domain.GenerateRandomAddress() // Fallback to random if no CEX addresses
	}

	// Simple random selection
	idx := int(g.state.GeneratedCount) % len(addresses)

	// Convert string address to Address type
	addr, err := g.parseAddressString(addresses[idx])
	if err != nil {
		return domain.GenerateRandomAddress() // Fallback on parse error
	}

	return addr
}

// parseAddressString converts hex string to Address type
func (g *TxFeeder) parseAddressString(hexStr string) (sharedDomain.Address, error) {
	var addr sharedDomain.Address

	// Remove 0x prefix if present
	if len(hexStr) >= 2 && hexStr[:2] == "0x" {
		hexStr = hexStr[2:]
	}

	if len(hexStr) != 40 {
		return addr, fmt.Errorf("invalid address length: %d", len(hexStr))
	}

	// Convert hex string to bytes
	for i := 0; i < 20; i++ {
		var b byte
		_, err := fmt.Sscanf(hexStr[i*2:i*2+2], "%02x", &b)
		if err != nil {
			return addr, err
		}
		addr[i] = b
	}

	return addr, nil
}

// sendToOutputChannels sends transaction to all registered output channels (backward compatibility)
func (g *TxFeeder) sendToOutputChannels(tx *sharedDomain.MarkedTransaction, ctx context.Context) {
	g.mutex.RLock()
	channels := g.requestedOutputChannels
	g.mutex.RUnlock()

	for _, ch := range channels {
		select {
		case ch <- tx:
			atomic.AddInt64(&g.stats.Transmitted, 1)
		case <-ctx.Done():
			return
		case <-g.stopChannel:
			return
		default:
			// Channel is full, drop the transaction
			atomic.AddInt64(&g.stats.Dropped, 1)
		}
	}
}

// sendToKafka sends transaction to fed-tx Kafka topic (ê³ ì„±ëŠ¥ ë¹„ë™ê¸°, ëª¨ë…¸ë¦¬ì‹ ìµœì í™”)
func (g *TxFeeder) sendToKafka(tx *sharedDomain.MarkedTransaction, ctx context.Context) {
	if g.kafkaProducer == nil {
		return // Kafka producer not initialized
	}

	// ëª¨ë…¸ë¦¬ì‹ í™˜ê²½ì´ë¯€ë¡œ í‚¤ëŠ” ë‹¨ìˆœí•˜ê²Œ (íŒŒí‹°ì…˜ ê³ ë ¤ ë¶ˆí•„ìš”)
	key := []byte("tx")

	// Send MarkedTransaction directly to Kafka (ì œë„ˆë¦­ íƒ€ì…ìœ¼ë¡œ ì§ì ‘ ì „ì†¡)
	if err := g.kafkaProducer.PublishMessage(ctx, key, tx); err != nil {
		// ë¹„ë™ê¸°ì—ì„œëŠ” ì£¼ë¡œ ë²„í¼ í’€ ì—ëŸ¬
		atomic.AddInt64(&g.stats.Dropped, 1)
		// ì—ëŸ¬ ë¡œê·¸ ìµœì†Œí™” (10000ê°œë§ˆë‹¤)
		if g.stats.Generated%10000 == 0 {
			fmt.Printf("   âš ï¸ Kafka buffer full (sample): %v\n", err)
		}
	} else {
		atomic.AddInt64(&g.stats.Transmitted, 1)
	}
}

// SetupEnvironment ê²©ë¦¬ëœ í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ ì„¤ì • (feed_and_analyze.goì—ì„œ ì´ë™)
func (g *TxFeeder) SetupEnvironment(envConfig *EnvironmentConfig) error {
	fmt.Println("\n2ï¸âƒ£ Preparing isolated environment...")

	g.baseDir = envConfig.BaseDir
	g.isolatedDir = envConfig.IsolatedDir

	// ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì œê±° í›„ ìƒˆë¡œ ìƒì„±
	os.RemoveAll(g.isolatedDir)
	if err := os.MkdirAll(g.isolatedDir, 0755); err != nil {
		return fmt.Errorf("failed to create isolated directory: %w", err)
	}

	// CEX ë°ì´í„° ë³µì œ
	sourceCEX := filepath.Join(g.baseDir, "shared", "txfeeder", "infra", "real_cex.txt")
	fmt.Printf("   ğŸ” Source CEX: %s\n", sourceCEX)
	fmt.Printf("   ğŸ” Target CEX: %s\n", envConfig.CEXFilePath)

	// ì†ŒìŠ¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
	if _, err := os.Stat(sourceCEX); os.IsNotExist(err) {
		return fmt.Errorf("source CEX file does not exist: %s", sourceCEX)
	}

	if err := g.copyFile(sourceCEX, envConfig.CEXFilePath); err != nil {
		return fmt.Errorf("failed to copy CEX file: %w", err)
	}

	// ë³µì‚¬ í›„ ê²€ì¦
	if copiedData, err := os.ReadFile(envConfig.CEXFilePath); err == nil {
		lines := strings.Split(string(copiedData), "\n")
		nonEmptyLines := 0
		for _, line := range lines {
			line = strings.TrimSpace(line)
			if line != "" && !strings.HasPrefix(line, "#") {
				nonEmptyLines++
			}
		}
		fmt.Printf("   ğŸ“„ CEX data copied - %d lines, %d addresses\n", len(lines), nonEmptyLines)
	} else {
		fmt.Printf("   âš ï¸  CEX data copied but could not verify: %v\n", err)
	}

	// ëª¨ì˜ ì…ê¸ˆ ì£¼ì†Œ ìƒì„±
	if err := g.createMockDeposits(envConfig.MockDepositFile); err != nil {
		return fmt.Errorf("failed to create mock deposits: %w", err)
	}
	fmt.Printf("   ğŸ“„ Mock deposits created\n")

	fmt.Printf("   âœ… Environment prepared\n")
	return nil
}

// LoadCEXSetFromFile CEX ì£¼ì†Œ ì§‘í•©ì„ íŒŒì¼ì—ì„œ ë¡œë“œ (ee/infra ê¸°ëŠ¥ ì´ë™)
func (g *TxFeeder) LoadCEXSetFromFile(cexFilePath string) (*sharedDomain.CEXSet, error) {
	fmt.Printf("   ğŸ” CEX file path: %s\n", cexFilePath)

	// íŒŒì¼ ì¡´ì¬ í™•ì¸
	if _, err := os.Stat(cexFilePath); os.IsNotExist(err) {
		return nil, fmt.Errorf("CEX file does not exist: %s", cexFilePath)
	}

	file, err := os.Open(cexFilePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open CEX file: %w", err)
	}
	defer file.Close()

	cexSet := sharedDomain.NewCEXSet()
	scanner := bufio.NewScanner(file)

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		// Skip empty lines and comments
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}

		cexAddr := sharedDomain.NewCEXAddress(line)
		if cexAddr.IsValid() {
			cexSet.Add(cexAddr.Address)
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, fmt.Errorf("failed to read CEX file: %w", err)
	}

	fmt.Printf("   ğŸ“¦ CEX addresses loaded: %d\n", cexSet.Size())

	// CEX ë¡œë”©ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì¶”ê°€ ë””ë²„ê¹…
	if cexSet.Size() == 0 {
		fmt.Printf("   âŒ CEX loading failed - checking file contents...\n")
		if fileData, err := os.ReadFile(cexFilePath); err == nil {
			lines := strings.Split(string(fileData), "\n")
			nonEmptyLines := 0
			for _, line := range lines {
				line = strings.TrimSpace(line)
				if line != "" && !strings.HasPrefix(line, "#") {
					nonEmptyLines++
				}
			}
			fmt.Printf("   ğŸ“„ File contains %d lines, %d non-empty non-comment lines\n", len(lines), nonEmptyLines)
		}
		return nil, fmt.Errorf("no CEX addresses loaded from file")
	}

	// CEX ì£¼ì†Œ ìƒ˜í”Œ ì¶œë ¥ (ë””ë²„ê¹…)
	cexAddresses := cexSet.GetAll()
	if len(cexAddresses) >= 3 {
		fmt.Printf("   ğŸ” CEX samples: %s, %s, %s\n",
			cexAddresses[0][:10]+"...",
			cexAddresses[1][:10]+"...",
			cexAddresses[2][:10]+"...")
	}

	g.cexSet = cexSet
	return cexSet, nil
}

// CleanupEnvironment ê²©ë¦¬ëœ í™˜ê²½ ì •ë¦¬ (feed_and_analyze.goì—ì„œ ì´ë™)
func (g *TxFeeder) CleanupEnvironment() {
	if g.isolatedDir == "" {
		return // ê²©ë¦¬ ë””ë ‰í† ë¦¬ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì •ë¦¬í•  ê²ƒì´ ì—†ìŒ
	}

	fmt.Println("\nğŸ§¹ Cleaning up isolated environment...")

	if err := os.RemoveAll(g.isolatedDir); err != nil {
		fmt.Printf("âš ï¸ Warning: cleanup failed: %v", err)
	} else {
		fmt.Printf("   âœ… Cleaned: %s\n", g.isolatedDir)
	}

	fmt.Println("ğŸ”’ No permanent changes to system")
}

// Close ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (íŠ¸ëœì­ì…˜ ìƒì„±ë§Œ ì¤‘ì§€, í™˜ê²½ ì •ë¦¬ëŠ” í˜¸ì¶œìê°€ ë‹´ë‹¹)
func (g *TxFeeder) Close() error {
	// Stopì„ í˜¸ì¶œí•´ì„œ íŠ¸ëœì­ì…˜ ìƒì„± ì¤‘ì§€
	g.Stop()

	// Kafka Producer ì •ë¦¬
	if g.kafkaProducer != nil {
		if err := g.kafkaProducer.Close(); err != nil {
			fmt.Printf("   âš ï¸ Kafka producer close error: %v\n", err)
		}
	}

	// Batch Producer ì •ë¦¬
	if g.batchProducer != nil {
		if err := g.batchProducer.Close(); err != nil {
			fmt.Printf("   âš ï¸ Batch producer close error: %v\n", err)
		}
	}

	return nil
}

// CleanupKafkaTopic í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ fed-tx í† í”½ ë°ì´í„° ì •ë¦¬
func (g *TxFeeder) CleanupKafkaTopic() error {
	if len(g.kafkaBrokers) == 0 {
		return nil
	}

	fmt.Println("ğŸ§¹ Cleaning up fed-tx Kafka topic...")

	if err := kafka.CleanupTopicComplete(g.kafkaBrokers, kafka.TestFedTxTopic, 1, 1); err != nil {
		fmt.Printf("   âš ï¸ Kafka topic cleanup warning: %v\n", err)
		return err
	}

	fmt.Printf("   âœ… Fed-tx topic cleaned up\n")
	return nil
}

// ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œë“¤ (feed_and_analyze.goì—ì„œ ì´ë™)
func (g *TxFeeder) copyFile(src, dst string) error {
	sourceFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer sourceFile.Close()

	destFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer destFile.Close()

	_, err = io.Copy(destFile, sourceFile)
	return err
}

func (g *TxFeeder) createMockDeposits(filePath string) error {
	fmt.Printf("   ğŸ” Creating mock deposit addresses at %s\n", filePath)
	file, err := os.Create(filePath)

	if err != nil {
		return err
	}
	defer file.Close()

	root := g.findProjectRoot()
	depositFilePath := filepath.Join(root, "shared", "txfeeder", "infra", "mocked_hidden_deposits.txt")
	fmt.Printf("loading mockedAndHiddenDepositAddress.txt from %s\n", depositFilePath)

	deposits, err := os.Open(depositFilePath)
	if err != nil {
		return err
	}
	defer deposits.Close()

	file.WriteString("# Mock Deposit Addresses for Fixed Queue Test\n\n")
	// í•œ ì¤„ì”© ì½ì–´ì„œ ë³µì‚¬
	scanner := bufio.NewScanner(deposits)
	totalLength := 0
	lineCount := 0
	for scanner.Scan() {
		line := scanner.Text()
		file.WriteString(line + "\n")
		totalLength += len(line)
		lineCount++
	}

	if err := scanner.Err(); err != nil {
		return fmt.Errorf("error reading deposit file: %w", err)
	}
	fmt.Printf("   âœ… Copied %d lines (total %d bytes of address strings)\n", lineCount, totalLength)
	return nil
}

// findProjectRoot í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (feed_and_analyze.goì—ì„œ ì´ë™)
func (g *TxFeeder) findProjectRoot() string {
	currentDir, _ := os.Getwd()

	for currentDir != "/" {
		if strings.HasSuffix(currentDir, "chainAnalyzer") {
			return currentDir
		}

		if data, err := os.ReadFile(filepath.Join(currentDir, "go.mod")); err == nil {
			if strings.Contains(string(data), "chainAnalyzer") {
				return currentDir
			}
		}

		currentDir = filepath.Dir(currentDir)
	}

	workingDir, _ := os.Getwd()
	return filepath.Join(workingDir, "../../../")
}
